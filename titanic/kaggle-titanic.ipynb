{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "# Standard Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "print(\"TF Version:\", tf.__version__)\n",
    "import sklearn.preprocessing as pre\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Titanic Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the goal is to predict whether, given a set of features of a given passenger aboard the titanic, they would have survived the shipwreck or not.\n",
    "\n",
    "The training data is comprised of these features for a collection of passengers, and whether they survived or not. Let's take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train = pd.read_csv('data/train.csv')\n",
    "raw_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "### Selecting features\n",
    "We can make the assumption that key fields, that contain unique values for each entry, are not useful sources of information, and will not be included in our feature representation. These are:\n",
    "- `PassengerId`\n",
    "- `Name`\n",
    "- `Ticket`\n",
    "\n",
    "Futher, we have holes in our data. The `Cabin` field is very sparsely populated, and the `Age` field is empty for about an 8th of our examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's not much we can do about the `Cabin` field. So we'll simply ignore it.\n",
    "\n",
    "Since the `Age` field has onyl a small amount of empty entries, we can approach this the following way:\n",
    "- Train a model `A` to estimate the missing ages, given the rest of the features\n",
    "- Fill in the gaps in the train and test data with model `A`\n",
    "- Train model `B` on to classify passengers as survived or not\n",
    "- Predict survived passengers from test data\n",
    "\n",
    "Our feature vectors will look like this:\n",
    "- $v_1$: Passenger Class\n",
    "- $v_2$: Sex $\\in \\{0,1\\}$\n",
    "- $v_3$: Age\n",
    "- $v_4$: Sib-Spouse Count\n",
    "- $v_5$: Parent-Child Count\n",
    "- $v_6$: Fare\n",
    "- $v_7$: Embarked $\\in \\{0,1,2\\}$\n",
    "\n",
    "Each of our feature vectors will then be normalized (by scaling them to standard normal distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature representations\n",
    "\n",
    "relevant_fields = [\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked\"]\n",
    "f_id = lambda x: x\n",
    "\n",
    "# Initially all encodings are just identity\n",
    "base_map = { feat:f_id for feat in relevant_fields }\n",
    "\n",
    "# Specific categorical encodings for sex and embark\n",
    "base_map[\"Sex\"] = lambda x: 0 if x == \"male\" else 1\n",
    "base_map[\"Embarked\"] = lambda x: 0 if x == \"C\" else 1 if x == \"Q\" else 2\n",
    "\n",
    "def mkrep(p,feat_map):\n",
    "    vec = np.empty(len(feat_map))\n",
    "    \n",
    "    for i, (feat, f) in enumerate(feat_map.items()):\n",
    "        vec[i] = f(p[feat])\n",
    "    \n",
    "    return vec\n",
    "\n",
    "def feat_reps(data, feat_map):\n",
    "    reps = np.empty((len(data), len(feat_map)))\n",
    "    for i in range(len(data)):\n",
    "        reps[i] = mkrep(data.iloc[i], feat_map)\n",
    "    return reps\n",
    "\n",
    "def standard_scale(feats):\n",
    "    scaler = pre.StandardScaler().fit(feats)\n",
    "    return scaler.transform(feats)\n",
    "\n",
    "def mk_dataset(df, feat_map, label=None, norm=None):\n",
    "    reps = feat_reps(df, feat_map)\n",
    "    reps_norm = norm(reps) if not norm is None else reps\n",
    "    labels = df[label].values\n",
    "    \n",
    "    if not label is None:\n",
    "        labels = df[label].values\n",
    "        return reps_norm, labels\n",
    "    else:\n",
    "        return reps_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll filter all our data to only contain relevant information. These will be our original, unadulterated data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = raw_train[relevant_fields]\n",
    "TEST = raw_test[relevant_fields]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model A - Estimating age\n",
    "Real values? This sounds like a job for linear regression! The features for model A will be given by all previously stated features, except age. We'll select all data where age is available, and make a 70:30 train:test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cba277c6d777>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# problem holds no relevance for the Age subproblem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcombined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTEST\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodelA_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbase_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"Age\"\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# We train model A on both original train and test data,\n",
    "# since the train-test split for the original classification\n",
    "# problem holds no relevance for the Age subproblem\n",
    "\n",
    "combined = pd.concat([TRAIN, TEST])\n",
    "\n",
    "modelA_map = { k:v for k,v in base_map.items() if k != \"Age\" }\n",
    "valid_ages = combined[combined.Age.notnull()]\n",
    "\n",
    "data_A, labels_A = mk_dataset(valid_ages, modelA_map, label=\"Age\", norm=standard_scale)\n",
    "\n",
    "train_AX = data_A[:800]\n",
    "train_AY = labels_A[:800]\n",
    "\n",
    "test_AX = data_A[800:]\n",
    "test_AY = labels_A[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
